---
title: Error Handling
description: Handle scraping errors gracefully with scrapex error types and recovery strategies.
---

import { Aside } from '@astrojs/starlight/components';

scrapex provides structured error handling to help you handle failures gracefully.

## ScrapeError

All scraping errors are instances of `ScrapeError`:

```typescript
import { scrape, ScrapeError } from 'scrapex';

try {
  const result = await scrape('https://example.com');
} catch (error) {
  if (error instanceof ScrapeError) {
    console.log('Code:', error.code);
    console.log('Message:', error.message);
    console.log('Status:', error.statusCode);
    console.log('Retryable:', error.isRetryable());
  }
}
```

## Error Codes

| Code | Description | Common Causes |
|------|-------------|---------------|
| `FETCH_FAILED` | Failed to fetch URL | Network issues, DNS failure |
| `TIMEOUT` | Request timed out | Slow server, network issues |
| `BLOCKED` | Access denied | 403 Forbidden, WAF blocking |
| `NOT_FOUND` | Page not found | 404 response |
| `PARSE_ERROR` | Failed to parse HTML | Malformed HTML |
| `ROBOTS_BLOCKED` | Blocked by robots.txt | `respectRobots: true` and disallowed |
| `INVALID_URL` | Invalid URL provided | Malformed URL string |
| `LLM_ERROR` | LLM provider failed | API error, rate limit, invalid key |
| `VALIDATION_ERROR` | Validation failed | Schema mismatch, invalid response |

## Handling Specific Errors

```typescript
import { scrape, ScrapeError } from 'scrapex';

async function safeScrape(url: string) {
  try {
    return await scrape(url, { timeout: 10000 });
  } catch (error) {
    if (!(error instanceof ScrapeError)) {
      throw error; // Re-throw unknown errors
    }

    switch (error.code) {
      case 'TIMEOUT':
        console.log(`Timeout scraping ${url}, retrying...`);
        return await scrape(url, { timeout: 30000 });

      case 'BLOCKED':
        if (error.statusCode === 429) {
          console.log('Rate limited, waiting...');
          await sleep(5000);
          return await scrape(url);
        }
        throw error;

      case 'NOT_FOUND':
        console.log('Page not found');
        return null;

      case 'ROBOTS_BLOCKED':
        console.log('Blocked by robots.txt, skipping');
        return null;

      default:
        throw error;
    }
  }
}
```

## Retry Logic

Implement exponential backoff for transient failures:

```typescript
async function scrapeWithRetry(
  url: string,
  maxRetries = 3,
  baseDelay = 1000
) {
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      return await scrape(url);
    } catch (error) {
      if (!(error instanceof ScrapeError)) throw error;

      // Use built-in isRetryable() or check specific codes
      const isRetryable = error.isRetryable() ||
                          (error.code === 'BLOCKED' && error.statusCode === 429);

      if (!isRetryable || attempt === maxRetries - 1) {
        throw error;
      }

      const delay = baseDelay * Math.pow(2, attempt);
      console.log(`Attempt ${attempt + 1} failed, retrying in ${delay}ms...`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
}
```

## Batch Scraping

Handle errors in batch operations:

```typescript
async function scrapeBatch(urls: string[]) {
  const results = await Promise.allSettled(
    urls.map(url => scrape(url))
  );

  const successful = [];
  const failed = [];

  for (let i = 0; i < results.length; i++) {
    const result = results[i];
    if (result.status === 'fulfilled') {
      successful.push(result.value);
    } else {
      failed.push({
        url: urls[i],
        error: result.reason,
      });
    }
  }

  console.log(`Success: ${successful.length}, Failed: ${failed.length}`);
  return { successful, failed };
}
```

## Error Logging

Create a structured error logger:

```typescript
function logScrapeError(error: ScrapeError, url: string) {
  // Use toJSON() for structured logging
  const entry = {
    timestamp: new Date().toISOString(),
    url,
    ...error.toJSON(),
  };

  console.error(JSON.stringify(entry));
  // Send to monitoring service
}
```

## Graceful Degradation

Return partial results when possible:

```typescript
async function scrapeWithFallback(url: string) {
  try {
    return await scrape(url, { llm: provider, enhance: ['summarize'] });
  } catch (error) {
    if (error instanceof ScrapeError && error.code === 'LLM_ERROR') {
      // LLM enhancement failed, try without it
      console.log('LLM enhancement failed, scraping without enhancement');
      return await scrape(url);
    }
    throw error;
  }
}
```

## Validation

Validate URLs before scraping:

```typescript
import { checkRobotsTxt, isValidUrl, scrape, ScrapeError } from 'scrapex';

async function validateAndScrape(url: string) {
  if (!isValidUrl(url)) {
    throw new ScrapeError(`Invalid URL: ${url}`, 'INVALID_URL');
  }

  // Optionally check robots.txt first
  try {
    const robotsCheck = await checkRobotsTxt(url);
    if (!robotsCheck.allowed) {
      throw new ScrapeError('Blocked by robots.txt', 'ROBOTS_BLOCKED');
    }
  } catch (error) {
    // Re-throw explicit blocks; only be permissive for infrastructure failures
    if (error instanceof ScrapeError && error.code === 'ROBOTS_BLOCKED') {
      throw error;
    }
    // If robots.txt check fails, you can either:
    // 1. Proceed with scraping (permissive)
    // 2. Fail the request (strict)
    console.warn('Failed to check robots.txt, proceeding anyway:', error);
  }

  return await scrape(url);
}
```

<Aside type="caution">
  Always validate user-provided URLs before scraping to prevent SSRF attacks and invalid requests.
</Aside>

## Error Recovery Patterns

### Circuit Breaker

Prevent cascading failures:

```typescript
class CircuitBreaker {
  private failures = 0;
  private lastFailure = 0;
  private readonly threshold = 5;
  private readonly resetTime = 60000; // 1 minute

  async execute<T>(fn: () => Promise<T>): Promise<T> {
    if (this.isOpen()) {
      throw new Error('Circuit breaker is open');
    }

    try {
      const result = await fn();
      this.failures = 0;
      return result;
    } catch (error) {
      this.failures++;
      this.lastFailure = Date.now();
      throw error;
    }
  }

  private isOpen(): boolean {
    if (this.failures >= this.threshold) {
      if (Date.now() - this.lastFailure > this.resetTime) {
        this.failures = 0; // Reset after timeout
        return false;
      }
      return true;
    }
    return false;
  }
}

const breaker = new CircuitBreaker();
const result = await breaker.execute(() => scrape(url));
```

## Next Steps

- [API Reference: scrape()](/api/scrape) - Full scrape function reference
- [Basic Scraping](/guides/basic-scraping) - Learn scraping fundamentals
