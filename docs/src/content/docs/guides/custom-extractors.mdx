---
title: Custom Extractors
description: Create domain-specific extractors to enhance scrapex with custom data extraction.
---

import { Aside, Steps } from '@astrojs/starlight/components';

scrapex uses an extensible extractor pipeline. You can create custom extractors to handle domain-specific data extraction.

## Extractor Interface

Every extractor implements the `Extractor` interface:

```typescript
import type { Extractor, ExtractionContext, ScrapedData } from 'scrapex';

interface Extractor {
  readonly name: string;      // Unique identifier
  readonly priority?: number; // Execution order (higher = earlier)
  extract(context: ExtractionContext): Promise<Partial<ScrapedData>>;
}
```

## Extraction Context

The `ExtractionContext` provides access to:

```typescript
interface ExtractionContext {
  url: string;             // Original URL
  finalUrl: string;        // Final URL after redirects
  html: string;            // Raw HTML
  $: CheerioAPI;           // Cheerio instance for DOM queries
  getDocument(): Document; // Lazy JSDOM document
  results: Partial<ScrapedData>;
  options: ScrapeOptions;  // Scraping options
}
```

## Creating a Custom Extractor

<Steps>

1. **Define the extractor class**

   ```typescript
   import type { Extractor, ExtractionContext, ScrapedData } from 'scrapex';

   class RecipeExtractor implements Extractor {
     readonly name = 'recipe';
     readonly priority = 60;

     async extract(context: ExtractionContext): Promise<Partial<ScrapedData>> {
       const { $ } = context;

       // Only handle pages with recipe schema
       if (!$('script[type="application/ld+json"]').text().includes('"Recipe"')) {
         return {};
       }

       // Extract recipe-specific data
       const ingredients = $('.ingredients li')
         .map((_, el) => $(el).text().trim())
         .get();

       const instructions = $('.instructions li')
         .map((_, el) => $(el).text().trim())
         .get();

       const prepTime = $('[itemprop="prepTime"]').attr('content');
       const cookTime = $('[itemprop="cookTime"]').attr('content');

       return {
         custom: {
           recipe: {
             ingredients,
             instructions,
             prepTime,
             cookTime,
           },
         },
       };
     }
   }
   ```

2. **Register the extractor**

   ```typescript
   import { scrapeHtml, createDefaultExtractors } from 'scrapex';

   const extractors = [...createDefaultExtractors(), new RecipeExtractor()];

   const result = await scrapeHtml(html, url, { extractors });
   ```

3. **Access custom data**

   ```typescript
   const recipe = result.custom?.recipe;
   if (recipe) {
     console.log('Ingredients:', recipe.ingredients);
     console.log('Instructions:', recipe.instructions);
   }
   ```

</Steps>

## Priority Levels

Extractors run in priority order (highest first). Built-in priorities:

| Priority | Extractor | Purpose |
|----------|-----------|---------|
| 100 | MetaExtractor | Title, description, author |
| 80 | JsonLdExtractor | Structured data |
| 70 | FaviconExtractor | Favicon discovery |
| 50 | ContentExtractor | Main content, Readability |
| 30 | LinksExtractor | Link extraction |

<Aside type="tip">
  Use priority 40-60 for custom extractors that should run alongside core content extraction.
</Aside>

## Conditional Extraction

Check conditions inside `extract()` and return `{}` when not applicable:

```typescript
class GitHubRepoExtractor implements Extractor {
  readonly name = 'github-repo';
  readonly priority = 55;

  async extract(context: ExtractionContext): Promise<Partial<ScrapedData>> {
    const { $ } = context;

    if (!context.url.includes('github.com') ||
        context.url.includes('/issues') ||
        context.url.includes('/pull')) {
      return {};
    }

    return {
      custom: {
        repo: {
          stars: parseInt($('.js-social-count').text().trim() || '0'),
          forks: $('[href$="/forks"] .Counter').text().trim(),
          language: $('[itemprop="programmingLanguage"]').text().trim(),
        },
      },
    };
  }
}
```

## Overriding Built-in Data

Custom extractors can override built-in fields:

```typescript
class BetterTitleExtractor implements Extractor {
  readonly name = 'better-title';
  readonly priority = 95; // Run after MetaExtractor (100)

  async extract(context: ExtractionContext): Promise<Partial<ScrapedData>> {
    const { $ } = context;

    // Use h1 if it's more descriptive than the page title
    const h1 = $('article h1, main h1').first().text().trim();
    const title = $('title').text().trim();

    if (h1 && h1.length > title.length * 0.5) {
      return { title: h1 };
    }

    return {};
  }
}
```

## TypeScript: Typing Custom Data

For type safety with custom data:

```typescript
interface ProductData {
  name: string;
  price: number;
  currency: string;
  inStock: boolean;
}

const result = await scrape(url, { extractors });
const product = result.custom?.product as ProductData | undefined;

if (product) {
  console.log(`${product.name}: ${product.currency}${product.price}`);
}
```

## Full Example

```typescript
import { scrape, createDefaultExtractors, type Extractor, type ExtractionContext, type ScrapedData } from 'scrapex';

class EcommerceExtractor implements Extractor {
  readonly name = 'ecommerce';
  readonly priority = 55;

  async extract(context: ExtractionContext): Promise<Partial<ScrapedData>> {
    const { $ } = context;

    if (
      $('[itemtype*="Product"]').length === 0 &&
      $('.product-price, .price').length === 0
    ) {
      return {};
    }

    const priceText = $('[itemprop="price"], .product-price, .price')
      .first()
      .text()
      .trim();

    const priceMatch = priceText.match(/[\d,.]+/);
    const price = priceMatch ? parseFloat(priceMatch[0].replace(',', '')) : null;

    const currency = priceText.match(/[$€£¥]/)?.[0] || 'USD';

    const inStock = $('[itemprop="availability"]').attr('content')?.includes('InStock') ??
                    !$('.out-of-stock, .sold-out').length;

    return {
      contentType: 'product',
      custom: {
        product: {
          name: $('[itemprop="name"], .product-title, h1').first().text().trim(),
          price,
          currency,
          inStock,
          sku: $('[itemprop="sku"]').text().trim() || undefined,
          brand: $('[itemprop="brand"]').text().trim() || undefined,
        },
      },
    };
  }
}

// Usage
const extractors = [...createDefaultExtractors(), new EcommerceExtractor()];
const result = await scrape('https://shop.example.com/product', { extractors });

console.log(result.contentType); // 'product'
console.log(result.custom?.product);
```

## Next Steps

- [Error Handling](/guides/error-handling) - Handle extraction failures gracefully
- [API Reference: Extractors](/api/extractors) - Full extractor API documentation
