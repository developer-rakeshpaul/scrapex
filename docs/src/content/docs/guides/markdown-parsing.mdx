---
title: Markdown Parsing
description: Parse Markdown files for sections, links, and code blocks.
---

import { Aside } from '@astrojs/starlight/components';

scrapex includes Markdown parsing for sections, links, and code blocks.

## MarkdownParser

The `MarkdownParser` class extracts sections, links, and code blocks from Markdown content:

```typescript
import { MarkdownParser } from 'scrapex/parsers';

const parser = new MarkdownParser();
const markdown = `
# My Document

Check out [Example](https://example.com) for more info.

## Section One

- [Link 1](https://one.com) - First link
- [Link 2](https://two.com) - Second link

## Section Two

More content with [another link](https://three.com).
`;

const result = parser.parse(markdown);
```

### Parsed Output

```typescript
console.log(result.data.sections);
// [
//   { level: 1, title: 'My Document', content: 'Check out Example for more info.', links: [...] },
//   { level: 2, title: 'Section One', content: '', links: [...] },
//   { level: 2, title: 'Section Two', content: 'More content with another link.', links: [...] },
// ]

console.log(result.data.links);
// [
//   { url: 'https://example.com', text: 'Example', context: 'My Document' },
//   { url: 'https://one.com', text: 'Link 1', context: 'Section One' },
//   { url: 'https://two.com', text: 'Link 2', context: 'Section One' },
//   { url: 'https://three.com', text: 'another link', context: 'Section Two' },
// ]
```

## Code Blocks

`MarkdownParser` also extracts fenced code blocks:

```typescript
console.log(result.data.codeBlocks);
// [{ language: 'bash', code: 'npm install ...', meta: undefined }]
```

## Filtering Links

Filter extracted links by domain or pattern:

```typescript
import { MarkdownParser } from 'scrapex/parsers';
import { extractDomain } from 'scrapex';

const parser = new MarkdownParser();
const result = parser.parse(markdown);

// Only GitHub links
const githubLinks = result.data.links.filter(
  link => extractDomain(link.url) === 'github.com'
);

// Only npm packages
const npmLinks = result.data.links.filter(
  link => link.url.includes('npmjs.com/package/')
);
```

<Aside type="tip">
  Use `extractDomain()` from scrapex for reliable domain extraction that handles subdomains.
</Aside>

## Next Steps

- [API Reference: Parsers](/api/parsers) - Full parser API documentation
- [Basic Scraping](/guides/basic-scraping) - Combine with web scraping
